% !Mode:: "TeX:UTF-8"

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:

% 学习排序知识库补全
\chapter{知识库补全预测模型}
\label{cha:kbc-rank}


\section{问题引入}
当前的知识库基于打分模型进行知识库补全有很大不足。一是知识库中正负实体对比例差别很大，对于每个在知识库中实际存在的三元组正实例，可能有成千上万条不存在的三元组负实例相对应，如三元组（北京师范大学，位于，中国）这个三元组在知识库中实际存在，是一条正实例，而（北京师范大学，位于，美国）和（北京师范大学，位于，日本）等上百条负实例与之对应，如何解决正负实体对不匹配的问题很关键，正负实体对比例悬殊，关系预测中仅靠打分是不够的。二是相关的方法都是通过评价三元组得分高低来预测结果的，而并未考虑候选实体对的顺序对预测结果的影响，也不关注候选实体的秩序关系，而基于学习排序的算法可以解决候选实体的秩序关系。

本部分研究基于抽取知识库中的关系路径特征进行模型预测。模型预测主要分为两种方法：
分类模型和排序模型。传统的基于逻辑回归的分类算法对正负实体对进行分类模型学习，
利用二分类算法学习正负实体对的得分，依据得分大小将正负实体对进行划分，从而进行关系预测。
排序模型通过构建排序算法，对一组正负实体对进行学习排序，通过学习实体对的秩序排名，期望能将
正实体对排在负实体对之前，这样既可获得比传统分类回归算法更好的结果。本研究构建了基于树排序方法的
知识库补全算法和基于神经网络排序的知识库补全算法。

本研究构建了一种新的知识库补全的模型。其知识库补全的技术关键点在于：
（1）给定一个输入关系，将输入关系切分为训练集（包括验证集）和测试集；
（2）对于训练集和测试集中的正实体对基于局部封闭世界的假设，生成对应比例的负实体对；
（3）将正负实体对构成的集合在由知识库构成的图中抽取特征，
基于随机游走的算法抽取从头实体对到尾实体对的路径类型作为关系预测的特征；
（4）构建学习排序模型，将生成的正负实体对进行模型训练，并将训练获得的模型为新的关系特征提供预测；
（5）基于MAP和MRR进行模型评价，改进模型的参数，更新模型获得更好的预测效果。

\section{基于逻辑回归的补全模型}

本研究的特征计算模块采用随机游走算法抽取给定关系下的路径类型特征。对一个给定的关系下的实体对，我们需要抽取在知识库中，能在有限路径长度下，从头实体到达尾实体的路径信息。对于如图1知识库中实体对(北京师范大学，中国)，我们在知识库中可以抽取路径类型信息如：(校长-生活在)、(位于-位于)、${有大学}^{-1}$-位于-位于)、(校长-出生-相邻-位于)等关系路径信息，并将这些关系路径信息作为学习排序的特征。通常，路径长度被限制在3-6跳之间，过高则关系路径太多，计算复杂度太高，而小于3跳的关系路径则使得获得关系路径类型信息太少，不能有效提供特征。

对于抽取到的特征，传统方法构建了一个分类器模型，学习每个关系和这个关系包含的实体对集合，将预测关系问题转化成一个分类预测问题，学习每个实体对具有某种关系的概率。
$$E_r=\{(h_i,t_j),y_i\}^N_{i=1} $$
表示关系r所有的实体对集合，其中$y_i\in \{0,1\}$，其中0表示负实体对，即知识库中并不是实际存在的三元组，
1表示正实体对，表示在知识库中实际存在的实体对，通过对知识库中的实体对进行分类器模型学习，
我们可以获得测试集合中实体对的打分情况。通常这个分类器采用逻辑回归算法进行模型的训练。
具体来说，对于每个关系的实体对，传统模型采用逻辑回归学习得到的关系路径特征向量$V_r$和实体属性特征向量$V_l$。
并定义了如下的逻辑回归函数，对每个关系下的实体对集合进行评价打分。
$$f(v,w)=\frac{1}{1+e^{w(V_r \oplus V_l)}}$$
其中w表示关系路径特征和实体属性特征的学习权重参数。经典论文采用对数似然函数进行最大似然估计，
并通过随机梯度下降算法学习这些模型的参数，除此之外，还考虑到模型的过拟合和参数正则化表示，本论文定义了如下的学习目标函数：
$$L_r=\frac{1}{N}\sum_{i=1}^N\{(y_ilog(f(v,w_r)) + (1-y_i)log(1-f(v,w_r))\}+\alpha ||w_r||+\beta||w_r^2||$$
其中，$L_r$表示给定关系r的目标函数，$\alpha$和$\beta$ 分别是$l_1$ 和$l_2$正则化惩罚项的权重，对于每个关系我们采用随机梯度下降算法使得整个训练集对数损失最小，同时结合$l_1$ 和$l_2$防止过拟合。最终我们可以学习得到每个关系下的关系路径特征和实体属性特征的权重。


\section{基于学习排序的树模型}
对于\label{sec:relational}中抽取的关系路径特征和\label{sec:literal}抽取的实体属性特征，我们需要构建基于学习排序算法的知识库补全模型进行关系训练和关系预测。
传统的路径排序算法中，当通过随机游走计算获得路径类型信息，并获得这些关系路径的值后，
再通过基于分类或者回归的算法，计算的到每个实体对的打分值，打分高的实体对排在打分低的实体对之前，
表示更可能是实际存在的实体对。而本技术不仅仅考虑实体对的打分高低，更关系实体对之间的排序关系，
正实体对总需要排序在负实体对前面，这样就能保证在预测的候选实体对中，总是排在前面的实体对是好的结果。
更具体的，我们采用一种学习排序的算法进行知识库补全。通过学习最小化实体对的pairwise损失函数，
直接优化MAP训练损失函数来进行模型参数更新，从而获得更好的模型预测结果。
我们使用基于LambdaMART的树的学习排序算法。对于一个给定的关系r，定义目标函数：
$$F(x_i|w,c)=\sum_{i=1}^K\alpha_i\pi(f_i)+\sum_{i=1}^Nl(f_i(x),f'_i(x))+\frac{C}{2}WW^T$$

其中第一项中的$\sum_{i=1}^K\alpha_i\pi(f_i)$是描述树复杂度的函数，总共有K个树进行模型训练。而第二项中$l(f_i(x),f'_i(x))$是模型的训练误差函数，
其中$f_i (x)$是每个实体对的实际分数，而$f'_i(x)$是通过模型学习得到的预测值，共训练了N轮，
训练误差函数可以根据实际需要改变，常见的训练误差函数可以选择MAP、AUC、NDCG等不同排序指标，
通常学习排序中MAP评价指标最为常见。考虑到我们目标函数是pairwise损失函数最小化，我们也选择MAP作为训练损失函数进行模型训练。
第三部分$\frac{C}{2}WW^T$是模型的惩罚项，是防止模型在训练数据中过拟合的L2惩罚函数。

\section{基于学习排序的知识库补全实验}
\label{cha:exp-relational}

本研究构建了一个面向YAGO2的知识库补全实例。YAGO是一个从维基百科上抽取的、包含地理名词、WordNet等数据的知识库，YAGO2是YAGO的一个实例。
当前YAGO2包括超过千万的实体和超过1.2亿的实体知识我们使用了其中实体的关系型三元组共有4,484,914条、37种关系类型。
我们按照37种不同的关系类型，将知识库切分为37份不同关系的实体对集合。
对于每个关系，我们首先基于知识库中的三元组抽取正实体对，对于每个由（头实体，尾实体）构成实体对，
基于局部封闭世界假设，使用当前关系中的其他实体随机替换生成10个负实体对，其中5个随机替换头实体，
5个随机替换尾实体。生成正负实体对后，我们按照4：1的比例将这些实体对切分为训练集合和测试集合，
这样就完成了知识库数据的预处理。

我们展示了基于YAGO2的总体MAP和MRR进行模型评价的结果。我们可以看到基于学习排序的知识库补全技术相比传统的路径排序算法在MAP上有很大的提升，
基于学习排序的算法相比传统的算法在YAGO2数据集上有近50\%的效果提升；而四种方法在MRR指标上效果相当，
基于学习排序算法的MRR并未比传统路径排序算法有显著下降。

我们详细分析了37种YAGO2中关系的MAP指标，并在表 \ref{rank}展示了部分关系的MAP值。
分析可以发现，大部分关系采用学习排序算法后，预测结果有较大的提高，而在不同的关系类型预测中，
MAP差别较大，如：“playFor”和“isConnectedTo”等关系预测有较大的提高，而在“isInterestedIn”等关系中关系预测提升较差。
总体来说，有超过30种关系的MAP预测获得了显著的提升，只有不到5种关系MAP预测结果并未有统计上的显著提升，
这样的实验说明基于学习排序算法的知识库补全技术相比传统的分类回归打分模型有非常大的效果提升。

\begin{table}[htbp]
  \centering
  \caption{学习排序补全算法部分关系MAP值}
    \begin{tabular}{|l|r|r|r|r|}
    \hline
    relation & \multicolumn{1}{l|}{PRA} & \multicolumn{1}{l|}{SFE} & \multicolumn{1}{l|}{rankPRA} & \multicolumn{1}{l|}{rankSFE} \\
    \hline
    actedIn & 0.3379  & 0.3496  & 0.6222  & 0.6252  \\
    \hline
    created & 0.2523  & 0.2532  & 0.3089  & 0.3128  \\
    \hline
    dealsWith & 0.1729  & 0.1411  & 0.1265  & 0.1572  \\
    \hline
    graduatedFrom & 0.2646  & 0.2726  & 0.5607  & 0.5726  \\
    \hline
    hasCapital & 0.5637  & 0.6014  & 0.7275  & 0.7304  \\
    \hline
    hasChild & 0.5004  & 0.5078  & 0.6674  & 0.6757  \\
    \hline
    influences & 0.2946  & 0.2932  & 0.5771  & 0.5836  \\
    \hline
    isAffiliatedTo & 0.6364  & 0.6538  & 0.7816  & 0.7840  \\
    \hline
    playsFor & 0.6538  & 0.6606  & 0.8020  & 0.8036  \\
    \hline
    wasBornIn & 0.3661  & 0.3742  & 0.6053  & 0.6070  \\
    \hline
    worksAt & 0.2343  & 0.2281  & 0.5022  & 0.5014  \\
    \hline
    wroteMusicFor & 0.3488  & 0.3621  & 0.6144  & 0.6161  \\
    \hline
    \end{tabular}%
  \label{rank}%
\end{table}%

\section{本章工作总结}
本章中，我们主要比较了基于逻辑回归分类模型和基于学习排序的树模型，通过优化知识库补全中的模型构建，我们使用基于pairwise的树排序模型，更好的提升了知识库补全中实体对之间的排序问题，将传统的基于逻辑回归的分类问题转化为基于学习排序的模型优化问题。
本研究通过对YAGO知识库进行试验发现，不同知识库补全模型中，基于排序的模型优化算法可以大幅提高正实体对在所有实体对中的秩序，从而能改变原有的知识库补全优化中仅仅对实体对进行打分的模式，能够获得更好的预测效果。对于多数关系而言，基于学习排序的树模型算法效果明显优于传统的逻辑回归分类算法。
