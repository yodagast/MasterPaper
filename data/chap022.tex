% !Mode:: "TeX:UTF-8"

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:

\chapter{知识库补全预测模型}

本论文基于抽取的实体属性特征和关系路径特征进行模型预测。模型预测主要分为两种方法：
分类模型和排序模型。传统的基于逻辑回归的分类算法对正负实体对进行分类模型学习，
利用二分类算法学习正负实体对的得分，依据得分大小将正负实体对进行划分，从而进行关系预测。
排序模型通过构建排序算法，对一组正负实体对进行学习排序，通过学习实体对的秩序排名，期望能将
正实体对排在负实体对之前，这样既可获得比传统分类回归算法更好的结果。本研究构建了基于树排序方法的
知识库补全算法和基于神经网络排序的知识库补全算法。
\label{sec:model}
\section{逻辑回归分类模型}
对于上述\label{sec:literal}和\label{sec:relational}抽取到的关系路径特征和实体属性特征。
传统方法构建了一个分类器模型，学习每个关系和这个关系包含的实体对集合，将预测关系问题转化成一个分类预测问题。
$E_r=\{(h_i,t_j),y_i\}^N_{i=1} $表示关系r所有的实体对集合，其中$y_i\in \{0,1\}$，其中0表示负实体对，即知识库中并不是实际存在的三元组，
1表示正实体对，表示在知识库中实际存在的实体对，通过对知识库中的实体对进行分类器模型学习，
我们可以获得测试集合中实体对的打分情况。通常这个分类器采用逻辑回归算法进行模型的训练。
具体来说，对于每个关系的实体对，传统模型采用逻辑回归学习得到的关系路径特征向量$V_r$和实体属性特征向量$V_l$。
并定义了如下的逻辑回归函数，对每个关系下的实体对集合进行评价打分。
$$f(v,w)=\frac{1}{1+e^{w(V_r \oplus V_l)}}$$
其中w表示关系路径特征和实体属性特征的学习权重参数。经典论文采用对数似然函数进行最大似然估计，
并通过随机梯度下降算法学习这些模型的参数，除此之外，还考虑到模型的过拟合和参数正则化表示，本论文定义了如下的
学习目标函数：
$$L_r=\frac{1}{N}\sum_{i=1}^N\{(y_ilog(f(v,w_r)) + (1-y_i)log(1-f(v,w_r))\}+\alpha ||w_r||+\beta||w_r^2||$$
其中，$L_r$表示给定关系r的目标函数，$\alpha$和$\beta$ 分别是$l_1$ 和$l_2$正则化惩罚项的权重，对于每个关系我们采用随机梯度下降算法使得整个训练集对数损失最小，同时结合$l_1$ 和$l_2$防止过拟合。最终我们可以学习得到每个关系下的关系路径特征和实体属性特征的权重。


\section{基于学习排序梯度下降树模型}
对于\label{sec:relational}中抽取的关系路径特征和\label{sec:literal}抽取的实体属性特征，我们需要构建基于学习排序算法的知识库补全模型进行关系训练和关系预测。
传统的路径排序算法中，当通过随机游走计算获得路径类型信息，并获得这些关系路径的值后，
再通过基于分类或者回归的算法，计算的到每个实体对的打分值，打分高的实体对排在打分低的实体对之前，
表示更可能是实际存在的实体对。而本技术不仅仅考虑实体对的打分高低，更关系实体对之间的排序关系，
正实体对总需要排序在负实体对前面，这样就能保证在预测的候选实体对中，总是排在前面的实体对是好的结果。
更具体的，我们采用一种学习排序的算法进行知识库补全。通过学习最小化实体对的pairwise损失函数，
直接优化MAP训练损失函数来进行模型参数更新，从而获得更好的模型预测结果。
我们使用基于LambdaMART的树的学习排序算法。对于一个给定的关系r，定义目标函数：
$$F(x_i|w,c)=\sum_{i=1}^K\alpha_i\pi(f_i)+\sum_{i=1}^Nl(f_i(x),f'_i(x))+\frac{C}{2}WW^T$$

其中第一项中的$\sum_{i=1}^K\alpha_i\pi(f_i)$是描述树复杂度的函数，总共有K个树进行模型训练。而第二项中$l(f_i(x),f'_i(x))$是模型的训练误差函数，
其中$f_i (x)$是每个实体对的实际分数，而$f'_i(x)$是通过模型学习得到的预测值，共训练了N轮，
训练误差函数可以根据实际需要改变，常见的训练误差函数可以选择MAP、AUC、NDCG等不同排序指标，
通常学习排序中MAP评价指标最为常见。考虑到我们目标函数是pairwise损失函数最小化，我们也选择MAP作为训练损失函数进行模型训练。
第三部分$\frac{C}{2}WW^T$是模型的惩罚项，是防止模型在训练数据中过拟合的L2惩罚函数。
